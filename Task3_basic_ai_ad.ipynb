{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ipf3BFynE7z"
   },
   "source": [
    "## Лабораторна робота №3.\n",
    "***Data Pre-Processing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICZ-L0GmwsCQ"
   },
   "source": [
    "Оцінювання даної роботи буде ураховувати якість ваших візуалізацій (вони можуть незначно відрізнятися від прикладів, але повинні змістовно відображати суть задачі) та опис отриманих вами результатів. При наявності ЛИШЕ візуалізацій без роз'яснень, робота оцінюватися НЕ БУДЕ.\n",
    "\n",
    "Під час виконання вам дозволено користуватися будь-якими зручними для вас бібліотеками для візуалізації. \n",
    "\n",
    "Роботи ідентифіковані як ІДЕНТИЧНІ одразу отримують 0 балів."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VobPhchjwsCQ"
   },
   "source": [
    "Для виконання цієї лабораторної роботи Вам необхідно скористатися вибіркою [titanic.csv](https://gist.github.com/michhar/2dfd2de0d4f8727f873422c5d959fff5).  \n",
    "Цей датасет ви вже використовували в лабораторній роботі №1 ;)  \n",
    "  \n",
    "  ```NB:побудовані графіки та гістограми мають бути змістовними і візуально зрозумілими.``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e_VyzaXuwsCR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgzSHX63wsCR"
   },
   "source": [
    "***Завдання 1.*** Перед початком роботи з будь яким датасетом, необхідно:  \n",
    "- завантажити датасет;  \n",
    "- вивести основну статистичну інформацію по числовим змінним;\n",
    "- вивести розмірність датасету;\n",
    "- перевірити типи змінних і кількість данних по кожній змінній."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:404\u001b[0m, in \u001b[0;36mPythonParser._infer_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 404\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffered_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_pos \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m hr:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:637\u001b[0m, in \u001b[0;36mPythonParser._buffered_line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:738\u001b[0m, in \u001b[0;36mPythonParser._next_line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 738\u001b[0m     orig_line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_iter_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:805\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[1;34m(self, row_num)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 805\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_clipboard\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./datasets/titanic.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m dataset\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\clipboards.py:129\u001b[0m, in \u001b[0;36mread_clipboard\u001b[1;34m(sep, dtype_backend, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sep) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    124\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_clipboard with regex separator does not work properly with c engine.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    126\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    127\u001b[0m     )\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStringIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:133\u001b[0m, in \u001b[0;36mPythonParser.__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_col_indices: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    128\u001b[0m columns: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]]\n\u001b[0;32m    129\u001b[0m (\n\u001b[0;32m    130\u001b[0m     columns,\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_original_columns,\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols,\n\u001b[1;32m--> 133\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Now self.columns has the set of columns that we will process.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# The original set is stored in self.original_columns.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'index_names'\u001b[39;00m\n\u001b[0;32m    138\u001b[0m (\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    146\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:432\u001b[0m, in \u001b[0;36mPythonParser._infer_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m columns, num_original_columns, unnamed_cols\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames:\n\u001b[1;32m--> 432\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EmptyDataError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo columns to parse from file\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    434\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames[:]\n\u001b[0;32m    436\u001b[0m this_columns: \u001b[38;5;28mlist\u001b[39m[Scalar \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_clipboard(\"./datasets/titanic.csv\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYji7E9OnE7_"
   },
   "source": [
    "***Завдання 2.*** Визначити кількість пропущених значень по кожному атрибуту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twyShYEfnE8A"
   },
   "source": [
    "***Завдання 3:*** Побудувати матрицю кореляції "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpUseKHooUGz"
   },
   "source": [
    "\n",
    "\n",
    "1.   Вирахувати кореляційні коефіціенти для набору данних за методом Пірсона\n",
    "2.   Відобразити отриману матрицю коефіціентів у вигляді теплокарти\n",
    "\n",
    "3. Описати отримані результати, спираючись на значення коефіціентів кореляції\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "\n",
    "correlation_matrix = numeric_dataset.corr(method='pearson')\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Кореляційна матриця\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyYa2kFGqolN"
   },
   "source": [
    "**Завдання 4:** Як ви могли помітити, у нашому датесеті досить багато пропущених значень, зокрема у атрибута віку пасажирів. Робота з такими даними впливае як на результат моделювання так і на загалом уявлення цілісної картини про дані. Тож для того, що позбавитися пропусків ми використаємо заповнення пропущених значень медіаною за групами.\n",
    "\n",
    "\n",
    "\n",
    "1.   Напишіть функцію, що на вхід приймає датафрейм, назву колонки з пропущеними значеннями та список групуючих колонок та повертає датафрейм з заповненими пропущеними значеннями\n",
    "2.   Наведіть приклад роботи функції та зробіть перевірку на пропущені значення (дивись **завдання 2**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_data(dataset, column, group_cols):\n",
    "    dataset = dataset.copy()  \n",
    "    dataset[column] = dataset[column].fillna(dataset.groupby(group_cols)[column].transform(\"median\"))\n",
    "    return dataset\n",
    "\n",
    "df_filled = fill_missing_data(dataset, \"Age\", [\"Pclass\", \"Sex\"])\n",
    "\n",
    "print(df_filled.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEQ5bESqnE8D"
   },
   "source": [
    " \n",
    "***Завдання 5:*** В моделях машинного навчання інснує велика проблема опрацювання безперервних змінних. Потрібно перетворити безперервні значення в категоріальні. \n",
    "\n",
    "Максимальний вік пасажира - ```80 років```.\n",
    "\n",
    "Отже, давайте розділимо діапазон від ```0 до 80``` на ```5``` осередків. \n",
    "\n",
    "\n",
    "Додайте до нашого датасету нову колонку ```Age_bin```, в якій будуть значення ```0, 1, 2, 3, 4```відповідно кожній віковій групі.\n",
    "\n",
    "Побудуйте графік, який відображає кількість виживших у кожній віковій категорії.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 16, 32, 48, 64, 80]\n",
    "labels = [0, 1, 2, 3, 4]\n",
    "dataset[\"Age_bin\"] = pd.cut(dataset[\"Age\"], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=\"Age_bin\", hue=\"Survived\", data=dataset, palette=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Вікова категорія\")\n",
    "plt.ylabel(\"Кількість пасажирів\")\n",
    "plt.title(\"Кількість виживших у кожній віковій категорії\")\n",
    "plt.legend(title=\"Вижив\", labels=[\"Не вижив\", \"Вижив\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMFZCUssnE8E"
   },
   "source": [
    "***Завдання 6:*** Так як змінна ```fare``` також є неперервною її треба закодувати до ```порядкової шкали``` \n",
    "Для цього скоритайтесь функцією ```pandas.qcut```.\n",
    "[pandas.qcut](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html)  \n",
    "- необхідно перевірити, чи є вірною гіпотеза про те, що кількість виживших пасажирів для квартильних значеннь змінної ```fare``` відрізняється, та чи доцільно використовувати кодування на цю змінну(для подальшої роботи з закодованою фичею)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Fare_category\"] = pd.qcut(dataset[\"Fare\"], q=4, labels=[1, 2, 3, 4])\n",
    "\n",
    "fare_survival_table = pd.crosstab(dataset[\"Fare_category\"], dataset[\"Survived\"], margins=True)\n",
    "\n",
    "\n",
    "fare_survival_table[\"Survival Rate (%)\"] = fare_survival_table[1] / fare_survival_table[\"All\"] * 100\n",
    "fare_survival_table = fare_survival_table.drop('All')\n",
    "\n",
    "fare_survival_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(fare_survival_table.index.astype(int), fare_survival_table[\"Survival Rate (%)\"], color='skyblue')\n",
    "\n",
    "plt.xlabel('Fare Category')\n",
    "plt.xticks(range(1, 5)) \n",
    "plt.ylabel('Survival Rate (%)')\n",
    "plt.title('Survival Rate by Fare Category')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReaEkYnbnE8F"
   },
   "source": [
    "***Завдання 7:*** Необхідно створити нові змінні ```Family_size``` та ```Alone``` та проаналізувати їх. Змінна ```Family_size``` передає суму змінних ```Parch``` та ```SibSp```. Змінна ```Family_size``` буде відібражати комбіновані дані, які необхідні для перевірки гіпотези, що ```виживання пасажирів залежіть від кількості членів їх сім'ї```. Змінна ```Alone``` позначає наявніть сім'ї."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обчислюємо загальний розмір сім'ї (кількість родичів на борту)\n",
    "dataset[\"Family_size\"] = dataset[\"Parch\"] + dataset[\"SibSp\"]\n",
    "\n",
    "dataset[\"Alone\"] = (dataset[\"Family_size\"] == 0).astype(int)\n",
    "\n",
    "dataset[\"Family_size\"].sum()\n",
    "\n",
    "family_survival = dataset.groupby(\"Family_size\")[\"Survived\"].mean() * 100\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(family_survival.index, family_survival, color='lightcoral')\n",
    "\n",
    "plt.xlabel(\"Family Size\")\n",
    "plt.ylabel(\"Survival Rate (%)\")\n",
    "plt.title(\"Survival Rate by Family Size\")\n",
    "plt.xticks(range(0, dataset[\"Family_size\"].max() + 1))\n",
    "plt.xlim(-0.5, dataset[\"Family_size\"].max() + 0.5) \n",
    "plt.show()\n",
    "\n",
    "# dataset[\"Family_size\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tynNQe7nE8H"
   },
   "source": [
    "***Завдання 8:*** Видалити атрибути які є ***НЕрелевантними*** або містять багато пропущених значень. Аргументувати свій вибір."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrkDsg1pnE8I"
   },
   "source": [
    "***Завдання 9:*** Перетворіть змінні ```Sex```, ```Embarked``` та ```Title``` в числові значення\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzHF2_WTnE8K"
   },
   "source": [
    "***Завдання 10.*** Побудувати графіки всіх категоріальних змінних та проаналізувати скільки кожна категорія містить даних\n",
    "\n",
    "1.   виділити категоріальні змінні \n",
    "2.   побудувати сітку графіків кількості спотрережень по кожній категорії\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cT1yoN3gwsCc"
   },
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8W168W_-wsCc"
   },
   "source": [
    "***Завдання 11.*** Побудувати діаграми розподілу всіх числових змінних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfDK5Kr_wsCc"
   },
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxCl26iPwsCc"
   },
   "source": [
    "##Співвіднонешшя між всіма числовими змінними \n",
    "  \n",
    "***Завдання 12.*** В деяких випадках візуалізація співвідношення між змінними (числовими, категоріальними) дає можливість побачити викиди в змінних та знайти приховані тенденції і виділити навіть додаткові змінні. Тому, необхідно:\n",
    "1) побудувати графіки співвідношення між всіма числовими змінними.  \n",
    "2) описати отримані співвідношення і запропонувати як їх можна (чи не можна) використати"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXvfNj3vwsCc"
   },
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваші висновки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv4URR2twsCd"
   },
   "source": [
    "Кожне правильно виконане завдання буде оцінюватись в ```2 бали```."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Task3_basic_ai_ad.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
